{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from PIL import Image\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data_20240124_sorted_small/insulting/1.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/2.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/3.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/4.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/5.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/6.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/7.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/8.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/9.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/10.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/11.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/12.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/13.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/14.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/15.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/16.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/17.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/18.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/19.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/20.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/21.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/22.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/23.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/24.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/25.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/26.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/27.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/28.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/29.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/30.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/31.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/32.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/33.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/34.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/35.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/36.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/37.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/38.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/39.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/40.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/41.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/42.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/43.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/44.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/45.jpg\n",
      "Failed to load image. or not exist\n",
      "./Data_20240124_sorted_small/insulting/46.jpg\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (100,300,3) into shape (300,310,100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img_2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     data_amount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 13\u001b[0m     train_image[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img_2)\n\u001b[0;32m     14\u001b[0m     train_label[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (100,300,3) into shape (300,310,100)"
     ]
    }
   ],
   "source": [
    "train_image = np.zeros((259,300,310,100))\n",
    "train_label = [None] * 203\n",
    "#创建数据集列表\n",
    "data_amount = 0\n",
    "\n",
    "#insulting\n",
    "for i in range(1,204):\n",
    "    data_place_one = './Data_20240124_sorted_small/insulting/' + str(i) + '.jpg'\n",
    "    print(data_place_one)\n",
    "    img_2 = cv2.imread(data_place_one)\n",
    "    if img_2 is not None:\n",
    "        data_amount += 1\n",
    "        train_image[i-1] = np.array(img_2)\n",
    "        train_label[i-1] = 1\n",
    "    else:\n",
    "        print(\"Failed to load image. or not exist\")\n",
    "\n",
    "#uninsulting\n",
    "for i in range(1,204):\n",
    "    data_place_one = './Data_20240124_sorted_small/uninsulting/' + str(i) + '.jpg'\n",
    "    print(data_place_one)\n",
    "    img_2 = cv2.imread(data_place_one)\n",
    "    if img_2 is not None:\n",
    "        data_amount += 1\n",
    "        train_image[i-1] = np.array(img_2)\n",
    "        train_label[i-1] = 0\n",
    "    else:\n",
    "        print(\"Failed to load image. or not exist\")\n",
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除空值\n",
    "train_label = [x for x in train_label if x != None]\n",
    "train_image = [x for x in train_image if np.any(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Victor\\AppData\\Local\\Temp\\ipykernel_12932\\1265955824.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_image = np.array(train_image)\n"
     ]
    }
   ],
   "source": [
    "#转换为np数组\n",
    "train_label = np.array(train_label)\n",
    "train_image = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = [x.astype(np.int64) for x in train_label]\n",
    "train_image = [x.astype(np.int64) for x in train_image]\n",
    "#train_image = train_image.astype(np.int64)\n",
    "#train_label = train_label.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 131, 100, 207, 96, 230, 118, 149, 100, 158, 224, 100, 126, 100, 150, 100, 50, 70, 56, 100, 140, 100, 132, 180, 162, 86, 200, 173, 134, 76, 100, 152, 100, 155, 90, 200, 280, 105, 273, 300, 150, 344, 120, 100, 198, 417, 224, 240, 147, 440, 200, 200, 225, 300, 170, 250, 150, 240, 286, 260, 162, 240, 150, 200, 200, 154, 225, 450, 200, 181, 200, 200, 200, 70, 200, 200, 200, 200, 200, 200, 149, 200, 100, 200, 200, 200, 191, 240, 150, 200, 440, 246, 440, 231, 237, 200, 168, 185, 216, 200, 100, 240, 400, 400, 185, 250, 172, 234, 197, 248, 440, 278, 263, 201, 348, 241, 200, 290, 263, 250, 300, 480, 500, 440, 332, 1200, 375, 500, 200, 240, 190, 240, 300, 240, 366, 564, 150, 378, 399, 269, 640, 580, 500, 240, 240, 500, 240, 345, 472, 400, 500, 435, 355, 240, 400, 240, 192, 400, 389, 500, 240, 440, 198, 239, 385, 135, 418, 441, 164, 640, 240\n  y sizes: 170\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_image\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\data_adapter.py:1950\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1943\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1944\u001b[0m         label,\n\u001b[0;32m   1945\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m   1946\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1947\u001b[0m         ),\n\u001b[0;32m   1948\u001b[0m     )\n\u001b[0;32m   1949\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1950\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 131, 100, 207, 96, 230, 118, 149, 100, 158, 224, 100, 126, 100, 150, 100, 50, 70, 56, 100, 140, 100, 132, 180, 162, 86, 200, 173, 134, 76, 100, 152, 100, 155, 90, 200, 280, 105, 273, 300, 150, 344, 120, 100, 198, 417, 224, 240, 147, 440, 200, 200, 225, 300, 170, 250, 150, 240, 286, 260, 162, 240, 150, 200, 200, 154, 225, 450, 200, 181, 200, 200, 200, 70, 200, 200, 200, 200, 200, 200, 149, 200, 100, 200, 200, 200, 191, 240, 150, 200, 440, 246, 440, 231, 237, 200, 168, 185, 216, 200, 100, 240, 400, 400, 185, 250, 172, 234, 197, 248, 440, 278, 263, 201, 348, 241, 200, 290, 263, 250, 300, 480, 500, 440, 332, 1200, 375, 500, 200, 240, 190, 240, 300, 240, 366, 564, 150, 378, 399, 269, 640, 580, 500, 240, 240, 500, 240, 345, 472, 400, 500, 435, 355, 240, 400, 240, 192, 400, 389, 500, 240, 440, 198, 239, 385, 135, 418, 441, 164, 640, 240\n  y sizes: 170\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()#初始化\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.fit((train_image),np.array(train_label),epochs=50,batch_size = 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
